{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3263df2-4ca9-4e2c-9a65-529776a46313",
   "metadata": {},
   "source": [
    "Предобработка датасета.\n",
    "\n",
    "Dataset preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc02896-c164-4cda-bd2e-5e66b85b86a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbd3487-aba3-422f-b7c5-40432167e51f",
   "metadata": {},
   "source": [
    "Загрузим БД.\n",
    "\n",
    "Downloading database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31daffe0-412c-498e-a5f7-ccf28185a806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-03 11:40:17--  https://life.bsc.es/pid/skempi2/database/download/skempi_v2.csv\n",
      "Resolving life.bsc.es (life.bsc.es)... 84.88.52.107\n",
      "Connecting to life.bsc.es (life.bsc.es)|84.88.52.107|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1602208 (1,5M) [text/csv]\n",
      "Saving to: ‘skempi_v2.csv.12’\n",
      "\n",
      "skempi_v2.csv.12    100%[===================>]   1,53M   476KB/s    in 3,3s    \n",
      "\n",
      "2025-05-03 11:40:24 (476 KB/s) - ‘skempi_v2.csv.12’ saved [1602208/1602208]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://life.bsc.es/pid/skempi2/database/download/skempi_v2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8231702-d6c1-4585-9e2e-c92b4fae23d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Pdb</th>\n",
       "      <th>Mutation(s)_PDB</th>\n",
       "      <th>Mutation(s)_cleaned</th>\n",
       "      <th>iMutation_Location(s)</th>\n",
       "      <th>Hold_out_type</th>\n",
       "      <th>Hold_out_proteins</th>\n",
       "      <th>Affinity_mut (M)</th>\n",
       "      <th>Affinity_mut_parsed</th>\n",
       "      <th>Affinity_wt (M)</th>\n",
       "      <th>Affinity_wt_parsed</th>\n",
       "      <th>...</th>\n",
       "      <th>koff_mut_parsed</th>\n",
       "      <th>koff_wt (s^(-1))</th>\n",
       "      <th>koff_wt_parsed</th>\n",
       "      <th>dH_mut (kcal mol^(-1))</th>\n",
       "      <th>dH_wt (kcal mol^(-1))</th>\n",
       "      <th>dS_mut (cal mol^(-1) K^(-1))</th>\n",
       "      <th>dS_wt (cal mol^(-1) K^(-1))</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Method</th>\n",
       "      <th>SKEMPI version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1CSE_E_I</td>\n",
       "      <td>LI45G</td>\n",
       "      <td>LI38G</td>\n",
       "      <td>COR</td>\n",
       "      <td>Pr/PI</td>\n",
       "      <td>Pr/PI</td>\n",
       "      <td>5.26E-11</td>\n",
       "      <td>5.260000e-11</td>\n",
       "      <td>1.12E-12</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IASP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1CSE_E_I</td>\n",
       "      <td>LI45S</td>\n",
       "      <td>LI38S</td>\n",
       "      <td>COR</td>\n",
       "      <td>Pr/PI</td>\n",
       "      <td>Pr/PI</td>\n",
       "      <td>8.33E-12</td>\n",
       "      <td>8.330000e-12</td>\n",
       "      <td>1.12E-12</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IASP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1CSE_E_I</td>\n",
       "      <td>LI45P</td>\n",
       "      <td>LI38P</td>\n",
       "      <td>COR</td>\n",
       "      <td>Pr/PI</td>\n",
       "      <td>Pr/PI</td>\n",
       "      <td>1.02E-07</td>\n",
       "      <td>1.020000e-07</td>\n",
       "      <td>1.12E-12</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IASP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1CSE_E_I</td>\n",
       "      <td>LI45I</td>\n",
       "      <td>LI38I</td>\n",
       "      <td>COR</td>\n",
       "      <td>Pr/PI</td>\n",
       "      <td>Pr/PI</td>\n",
       "      <td>1.72E-10</td>\n",
       "      <td>1.720000e-10</td>\n",
       "      <td>1.12E-12</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IASP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1CSE_E_I</td>\n",
       "      <td>LI45D</td>\n",
       "      <td>LI38D</td>\n",
       "      <td>COR</td>\n",
       "      <td>Pr/PI</td>\n",
       "      <td>Pr/PI</td>\n",
       "      <td>1.92E-09</td>\n",
       "      <td>1.920000e-09</td>\n",
       "      <td>1.12E-12</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IASP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>3QIB_ABP_CD</td>\n",
       "      <td>KP9R</td>\n",
       "      <td>KP8R</td>\n",
       "      <td>COR</td>\n",
       "      <td>TCR/pMHC</td>\n",
       "      <td>TCR/pMHC,1JCK_A_B</td>\n",
       "      <td>2.4E-04</td>\n",
       "      <td>2.400000e-04</td>\n",
       "      <td>5.5E-06</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500</td>\n",
       "      <td>2.2E-02</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPR</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>3QIB_ABP_CD</td>\n",
       "      <td>TP12A</td>\n",
       "      <td>TP11A</td>\n",
       "      <td>COR</td>\n",
       "      <td>TCR/pMHC</td>\n",
       "      <td>TCR/pMHC,1JCK_A_B</td>\n",
       "      <td>&gt;1.1E-03</td>\n",
       "      <td>1.100000e-03</td>\n",
       "      <td>5.5E-06</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPR</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>3QIB_ABP_CD</td>\n",
       "      <td>TP12S</td>\n",
       "      <td>TP11S</td>\n",
       "      <td>COR</td>\n",
       "      <td>TCR/pMHC</td>\n",
       "      <td>TCR/pMHC,1JCK_A_B</td>\n",
       "      <td>3.38E-05</td>\n",
       "      <td>3.380000e-05</td>\n",
       "      <td>5.5E-06</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2.2E-02</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPR</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>3QIB_ABP_CD</td>\n",
       "      <td>TP12N</td>\n",
       "      <td>TP11N</td>\n",
       "      <td>COR</td>\n",
       "      <td>TCR/pMHC</td>\n",
       "      <td>TCR/pMHC,1JCK_A_B</td>\n",
       "      <td>4.34E-05</td>\n",
       "      <td>4.340000e-05</td>\n",
       "      <td>5.5E-06</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175</td>\n",
       "      <td>2.2E-02</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPR</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7084</th>\n",
       "      <td>3QIB_ABP_CD</td>\n",
       "      <td>YP7F,TP12S</td>\n",
       "      <td>YP6F,TP11S</td>\n",
       "      <td>COR,COR</td>\n",
       "      <td>TCR/pMHC</td>\n",
       "      <td>TCR/pMHC,1JCK_A_B</td>\n",
       "      <td>4.29E-05</td>\n",
       "      <td>4.290000e-05</td>\n",
       "      <td>5.5E-06</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180</td>\n",
       "      <td>2.2E-02</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SPR</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7085 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             #Pdb Mutation(s)_PDB Mutation(s)_cleaned iMutation_Location(s)  \\\n",
       "0        1CSE_E_I           LI45G               LI38G                   COR   \n",
       "1        1CSE_E_I           LI45S               LI38S                   COR   \n",
       "2        1CSE_E_I           LI45P               LI38P                   COR   \n",
       "3        1CSE_E_I           LI45I               LI38I                   COR   \n",
       "4        1CSE_E_I           LI45D               LI38D                   COR   \n",
       "...           ...             ...                 ...                   ...   \n",
       "7080  3QIB_ABP_CD            KP9R                KP8R                   COR   \n",
       "7081  3QIB_ABP_CD           TP12A               TP11A                   COR   \n",
       "7082  3QIB_ABP_CD           TP12S               TP11S                   COR   \n",
       "7083  3QIB_ABP_CD           TP12N               TP11N                   COR   \n",
       "7084  3QIB_ABP_CD      YP7F,TP12S          YP6F,TP11S               COR,COR   \n",
       "\n",
       "     Hold_out_type  Hold_out_proteins Affinity_mut (M)  Affinity_mut_parsed  \\\n",
       "0            Pr/PI              Pr/PI         5.26E-11         5.260000e-11   \n",
       "1            Pr/PI              Pr/PI         8.33E-12         8.330000e-12   \n",
       "2            Pr/PI              Pr/PI         1.02E-07         1.020000e-07   \n",
       "3            Pr/PI              Pr/PI         1.72E-10         1.720000e-10   \n",
       "4            Pr/PI              Pr/PI         1.92E-09         1.920000e-09   \n",
       "...            ...                ...              ...                  ...   \n",
       "7080      TCR/pMHC  TCR/pMHC,1JCK_A_B          2.4E-04         2.400000e-04   \n",
       "7081      TCR/pMHC  TCR/pMHC,1JCK_A_B         >1.1E-03         1.100000e-03   \n",
       "7082      TCR/pMHC  TCR/pMHC,1JCK_A_B         3.38E-05         3.380000e-05   \n",
       "7083      TCR/pMHC  TCR/pMHC,1JCK_A_B         4.34E-05         4.340000e-05   \n",
       "7084      TCR/pMHC  TCR/pMHC,1JCK_A_B         4.29E-05         4.290000e-05   \n",
       "\n",
       "     Affinity_wt (M)  Affinity_wt_parsed  ... koff_mut_parsed  \\\n",
       "0           1.12E-12        1.120000e-12  ...             NaN   \n",
       "1           1.12E-12        1.120000e-12  ...             NaN   \n",
       "2           1.12E-12        1.120000e-12  ...             NaN   \n",
       "3           1.12E-12        1.120000e-12  ...             NaN   \n",
       "4           1.12E-12        1.120000e-12  ...             NaN   \n",
       "...              ...                 ...  ...             ...   \n",
       "7080         5.5E-06        5.500000e-06  ...           0.500   \n",
       "7081         5.5E-06        5.500000e-06  ...             NaN   \n",
       "7082         5.5E-06        5.500000e-06  ...           0.134   \n",
       "7083         5.5E-06        5.500000e-06  ...           0.175   \n",
       "7084         5.5E-06        5.500000e-06  ...           0.180   \n",
       "\n",
       "     koff_wt (s^(-1)) koff_wt_parsed dH_mut (kcal mol^(-1))  \\\n",
       "0                 NaN            NaN                    NaN   \n",
       "1                 NaN            NaN                    NaN   \n",
       "2                 NaN            NaN                    NaN   \n",
       "3                 NaN            NaN                    NaN   \n",
       "4                 NaN            NaN                    NaN   \n",
       "...               ...            ...                    ...   \n",
       "7080          2.2E-02          0.022                    NaN   \n",
       "7081              NaN            NaN                    NaN   \n",
       "7082          2.2E-02          0.022                    NaN   \n",
       "7083          2.2E-02          0.022                    NaN   \n",
       "7084          2.2E-02          0.022                    NaN   \n",
       "\n",
       "      dH_wt (kcal mol^(-1))  dS_mut (cal mol^(-1) K^(-1))  \\\n",
       "0                       NaN                           NaN   \n",
       "1                       NaN                           NaN   \n",
       "2                       NaN                           NaN   \n",
       "3                       NaN                           NaN   \n",
       "4                       NaN                           NaN   \n",
       "...                     ...                           ...   \n",
       "7080                    NaN                           NaN   \n",
       "7081                    NaN                           NaN   \n",
       "7082                    NaN                           NaN   \n",
       "7083                    NaN                           NaN   \n",
       "7084                    NaN                           NaN   \n",
       "\n",
       "      dS_wt (cal mol^(-1) K^(-1))  Notes Method  SKEMPI version  \n",
       "0                             NaN    NaN   IASP               1  \n",
       "1                             NaN    NaN   IASP               1  \n",
       "2                             NaN    NaN   IASP               1  \n",
       "3                             NaN    NaN   IASP               1  \n",
       "4                             NaN    NaN   IASP               1  \n",
       "...                           ...    ...    ...             ...  \n",
       "7080                          NaN    NaN    SPR               2  \n",
       "7081                          NaN    NaN    SPR               2  \n",
       "7082                          NaN    NaN    SPR               2  \n",
       "7083                          NaN    NaN    SPR               2  \n",
       "7084                          NaN    NaN    SPR               2  \n",
       "\n",
       "[7085 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inidata = pd.read_csv(f'skempi_v2.csv', sep=';')\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "inidata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e50279-c8b2-48d5-a924-9e0398696cb9",
   "metadata": {},
   "source": [
    "Согласно [статье](https://academic.oup.com/bioinformatics/article/35/3/462/5055583) для расчета $\\Delta G$ достаточно знать температуру (столбец `Temperature`) и $K_D$, которая соответствует значениям в колонках `Affinity_mut_parsed` и `Affinity_wt_parsed` (статья: \"the wild-type and mutant affinities ($K_D$, M)\"). Оставляем соотвественные столбцы. Необходимо как-то конкретизировать сами мутации. PDB-идентификаторы несут слишком конкретную информацию, поэтому если мы хотим научиться предсказывать изменение знака $\\Delta G$, то это информация будет избыточной. Имеет смысл рассматривать, какие белки находятся в комплексе (`Protein 1`, `Protein 2`), положение мутаций в белках (`iMutation_Location(s)` и очищенный от информации про конкретные положения мутированных аиноксилот столбец `Mutation(s)_cleaned` - будем смотреть только на \"тип\" мутации - с какой на какую аминоксилоту проиходит замена). Можно было бы еще рассмотреть тип комплекса (`Hold_out_type`), но он определен не для всего, поэтому была бы большая потеря информации, когда стали бы удалять строки с NaN.\n",
    "Удалим все остальные столбцы.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b30a9a2-b9f7-4e06-aaff-9c5daeb1e791",
   "metadata": {},
   "source": [
    "According to the [paper](https://academic.oup.com/bioinformatics/article/35/3/462/5055583), to calculate ΔG it is sufficient to know the temperature (column `Temperature`) and the dissociation constant \\( K_D \\), which corresponds to the values in the columns `Affinity_mut_parsed` and `Affinity_wt_parsed` (\"the wild-type and mutant affinities (\\(K_D\\), M)\"). We will keep these relevant columns.\n",
    "\n",
    "It is necessary to specify the mutations more concretely. The PDB identifiers contain overly specific information, so if we aim to predict the sign change of ΔG, this data would be excessive. It is more reasonable to consider which proteins form the complex (`Protein 1`, `Protein 2`), the mutation positions within the proteins (`iMutation_Location(s)`), and the column `Mutation(s)_cleaned` with positional data removed (we will only look at the “type” of mutation — which amino acid is replaced by which).  \n",
    "\n",
    "We could also consider the type of complex (`Hold_out_type`), but since it is not defined for all entries, removing rows with missing values (NaN) would lead to excessive data loss.  \n",
    "\n",
    "All other columns will be removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9434a70-5b6a-4f16-a4ac-fec1b67b3d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mutation(s)_cleaned</th>\n",
       "      <th>iMutation_Location(s)</th>\n",
       "      <th>Affinity_mut_parsed</th>\n",
       "      <th>Affinity_wt_parsed</th>\n",
       "      <th>Protein 1</th>\n",
       "      <th>Protein 2</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LI38G</td>\n",
       "      <td>COR</td>\n",
       "      <td>5.260000e-11</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LI38S</td>\n",
       "      <td>COR</td>\n",
       "      <td>8.330000e-12</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LI38P</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.020000e-07</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LI38I</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.720000e-10</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LI38D</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.920000e-09</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>KP8R</td>\n",
       "      <td>COR</td>\n",
       "      <td>2.400000e-04</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>TP11A</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.100000e-03</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>TP11S</td>\n",
       "      <td>COR</td>\n",
       "      <td>3.380000e-05</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>TP11N</td>\n",
       "      <td>COR</td>\n",
       "      <td>4.340000e-05</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7084</th>\n",
       "      <td>YP6F,TP11S</td>\n",
       "      <td>COR,COR</td>\n",
       "      <td>4.290000e-05</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7085 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mutation(s)_cleaned iMutation_Location(s)  Affinity_mut_parsed  \\\n",
       "0                  LI38G                   COR         5.260000e-11   \n",
       "1                  LI38S                   COR         8.330000e-12   \n",
       "2                  LI38P                   COR         1.020000e-07   \n",
       "3                  LI38I                   COR         1.720000e-10   \n",
       "4                  LI38D                   COR         1.920000e-09   \n",
       "...                  ...                   ...                  ...   \n",
       "7080                KP8R                   COR         2.400000e-04   \n",
       "7081               TP11A                   COR         1.100000e-03   \n",
       "7082               TP11S                   COR         3.380000e-05   \n",
       "7083               TP11N                   COR         4.340000e-05   \n",
       "7084          YP6F,TP11S               COR,COR         4.290000e-05   \n",
       "\n",
       "      Affinity_wt_parsed              Protein 1 Protein 2 Temperature  \n",
       "0           1.120000e-12   Subtilisin Carlsberg   Eglin c         294  \n",
       "1           1.120000e-12   Subtilisin Carlsberg   Eglin c         294  \n",
       "2           1.120000e-12   Subtilisin Carlsberg   Eglin c         294  \n",
       "3           1.120000e-12   Subtilisin Carlsberg   Eglin c         294  \n",
       "4           1.120000e-12   Subtilisin Carlsberg   Eglin c         294  \n",
       "...                  ...                    ...       ...         ...  \n",
       "7080        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298  \n",
       "7081        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298  \n",
       "7082        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298  \n",
       "7083        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298  \n",
       "7084        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298  \n",
       "\n",
       "[7085 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=inidata.drop(columns=['#Pdb','dH_mut (kcal mol^(-1))','dH_wt (kcal mol^(-1))', 'dS_mut (cal mol^(-1) K^(-1))', 'dS_wt (cal mol^(-1) K^(-1))','kon_mut_parsed','kon_wt_parsed','koff_mut_parsed','koff_wt_parsed','koff_wt (s^(-1))','koff_mut (s^(-1))','kon_wt (M^(-1)s^(-1))','kon_mut (M^(-1)s^(-1))','Mutation(s)_PDB', 'Affinity_mut (M)','Affinity_wt (M)','Hold_out_type', 'Method', 'Notes', 'SKEMPI version', 'Hold_out_proteins', 'Reference'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc658c-3dda-473b-a41f-8c9ee566c6be",
   "metadata": {},
   "source": [
    "Проверим на вырожденность датасета: вдруг встречаются записи для белков, в которых просто Protein 1 и Protein 2 поменяны местами\n",
    "\n",
    "Let's check the dataset for degeneracy: it is possible that there are entries where the values of `Protein 1` and `Protein 2` are simply swapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74aecfc2-40ca-4b2b-b615-a84a0e7e9d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Mutation(s)_cleaned, iMutation_Location(s), Affinity_mut_parsed, Affinity_wt_parsed, Protein 1, Protein 2, Temperature]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "mask = data.apply(\n",
    "    lambda row: ((data['Protein 1'] == row['Protein 2']) & (data['Protein 2'] == row['Protein 1'])).any(),\n",
    "    axis=1\n",
    ")\n",
    "print(data[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fb0a32-b150-40be-a89c-f0458b4841c7",
   "metadata": {},
   "source": [
    "Отлично, таких нет, поэтому удалим какие либо NaN (надо заметить, что их немного, так что в целом большого потери информации не будет).\n",
    "\n",
    "We will remove all rows with NaN values in the dataset, given that such values are few and their removal will not significantly affect the information content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33b61d26-156b-45d0-a783-6bf07c4dd62d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291\n"
     ]
    }
   ],
   "source": [
    "datanan = data[data['Affinity_wt_parsed'].isna() | data['Affinity_mut_parsed'].isna() | data['Temperature'].isna() | \n",
    "data['iMutation_Location(s)'].isna() | data['Protein 1'].isna() |\tdata['Protein 2'].isna() | data['Mutation(s)_cleaned'].isna()]\n",
    "print(len(datanan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32ec633-67f5-4854-953c-dda1b8fbbd48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mutation(s)_cleaned</th>\n",
       "      <th>iMutation_Location(s)</th>\n",
       "      <th>Affinity_mut_parsed</th>\n",
       "      <th>Affinity_wt_parsed</th>\n",
       "      <th>Protein 1</th>\n",
       "      <th>Protein 2</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LI38G</td>\n",
       "      <td>COR</td>\n",
       "      <td>5.260000e-11</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LI38S</td>\n",
       "      <td>COR</td>\n",
       "      <td>8.330000e-12</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LI38P</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.020000e-07</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LI38I</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.720000e-10</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LI38D</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.920000e-09</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>KP8R</td>\n",
       "      <td>COR</td>\n",
       "      <td>2.400000e-04</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>TP11A</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.100000e-03</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>TP11S</td>\n",
       "      <td>COR</td>\n",
       "      <td>3.380000e-05</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>TP11N</td>\n",
       "      <td>COR</td>\n",
       "      <td>4.340000e-05</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7084</th>\n",
       "      <td>YP6F,TP11S</td>\n",
       "      <td>COR,COR</td>\n",
       "      <td>4.290000e-05</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6794 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mutation(s)_cleaned iMutation_Location(s)  Affinity_mut_parsed  \\\n",
       "0                  LI38G                   COR         5.260000e-11   \n",
       "1                  LI38S                   COR         8.330000e-12   \n",
       "2                  LI38P                   COR         1.020000e-07   \n",
       "3                  LI38I                   COR         1.720000e-10   \n",
       "4                  LI38D                   COR         1.920000e-09   \n",
       "...                  ...                   ...                  ...   \n",
       "7080                KP8R                   COR         2.400000e-04   \n",
       "7081               TP11A                   COR         1.100000e-03   \n",
       "7082               TP11S                   COR         3.380000e-05   \n",
       "7083               TP11N                   COR         4.340000e-05   \n",
       "7084          YP6F,TP11S               COR,COR         4.290000e-05   \n",
       "\n",
       "      Affinity_wt_parsed              Protein 1 Protein 2 Temperature  \n",
       "0           1.120000e-12   Subtilisin Carlsberg   Eglin c         294  \n",
       "1           1.120000e-12   Subtilisin Carlsberg   Eglin c         294  \n",
       "2           1.120000e-12   Subtilisin Carlsberg   Eglin c         294  \n",
       "3           1.120000e-12   Subtilisin Carlsberg   Eglin c         294  \n",
       "4           1.120000e-12   Subtilisin Carlsberg   Eglin c         294  \n",
       "...                  ...                    ...       ...         ...  \n",
       "7080        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298  \n",
       "7081        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298  \n",
       "7082        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298  \n",
       "7083        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298  \n",
       "7084        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298  \n",
       "\n",
       "[6794 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna(subset=['Affinity_wt_parsed','Affinity_mut_parsed', 'Temperature', 'iMutation_Location(s)', 'Mutation(s)_cleaned', 'Protein 1', 'Protein 2'])\n",
    "data = data.copy()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7fe29a4-c019-45cf-b742-08a64e4314f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mutation(s)_cleaned</th>\n",
       "      <th>iMutation_Location(s)</th>\n",
       "      <th>Affinity_mut_parsed</th>\n",
       "      <th>Affinity_wt_parsed</th>\n",
       "      <th>Protein 1</th>\n",
       "      <th>Protein 2</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>orig_A_COR</th>\n",
       "      <th>mut_A_COR</th>\n",
       "      <th>orig_A_INT</th>\n",
       "      <th>...</th>\n",
       "      <th>orig_Y_COR</th>\n",
       "      <th>mut_Y_COR</th>\n",
       "      <th>orig_Y_INT</th>\n",
       "      <th>mut_Y_INT</th>\n",
       "      <th>orig_Y_SUR</th>\n",
       "      <th>mut_Y_SUR</th>\n",
       "      <th>orig_Y_RIM</th>\n",
       "      <th>mut_Y_RIM</th>\n",
       "      <th>orig_Y_SUP</th>\n",
       "      <th>mut_Y_SUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LI38G</td>\n",
       "      <td>COR</td>\n",
       "      <td>5.260000e-11</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LI38S</td>\n",
       "      <td>COR</td>\n",
       "      <td>8.330000e-12</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LI38P</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.020000e-07</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LI38I</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.720000e-10</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LI38D</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.920000e-09</td>\n",
       "      <td>1.120000e-12</td>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>KP8R</td>\n",
       "      <td>COR</td>\n",
       "      <td>2.400000e-04</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>TP11A</td>\n",
       "      <td>COR</td>\n",
       "      <td>1.100000e-03</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>TP11S</td>\n",
       "      <td>COR</td>\n",
       "      <td>3.380000e-05</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>TP11N</td>\n",
       "      <td>COR</td>\n",
       "      <td>4.340000e-05</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7084</th>\n",
       "      <td>YP6F,TP11S</td>\n",
       "      <td>COR,COR</td>\n",
       "      <td>4.290000e-05</td>\n",
       "      <td>5.500000e-06</td>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6794 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Mutation(s)_cleaned iMutation_Location(s)  Affinity_mut_parsed  \\\n",
       "0                  LI38G                   COR         5.260000e-11   \n",
       "1                  LI38S                   COR         8.330000e-12   \n",
       "2                  LI38P                   COR         1.020000e-07   \n",
       "3                  LI38I                   COR         1.720000e-10   \n",
       "4                  LI38D                   COR         1.920000e-09   \n",
       "...                  ...                   ...                  ...   \n",
       "7080                KP8R                   COR         2.400000e-04   \n",
       "7081               TP11A                   COR         1.100000e-03   \n",
       "7082               TP11S                   COR         3.380000e-05   \n",
       "7083               TP11N                   COR         4.340000e-05   \n",
       "7084          YP6F,TP11S               COR,COR         4.290000e-05   \n",
       "\n",
       "      Affinity_wt_parsed              Protein 1 Protein 2 Temperature  \\\n",
       "0           1.120000e-12   Subtilisin Carlsberg   Eglin c         294   \n",
       "1           1.120000e-12   Subtilisin Carlsberg   Eglin c         294   \n",
       "2           1.120000e-12   Subtilisin Carlsberg   Eglin c         294   \n",
       "3           1.120000e-12   Subtilisin Carlsberg   Eglin c         294   \n",
       "4           1.120000e-12   Subtilisin Carlsberg   Eglin c         294   \n",
       "...                  ...                    ...       ...         ...   \n",
       "7080        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298   \n",
       "7081        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298   \n",
       "7082        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298   \n",
       "7083        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298   \n",
       "7084        5.500000e-06  I-Ek plus MCC peptide   2B4 TCR         298   \n",
       "\n",
       "      orig_A_COR  mut_A_COR  orig_A_INT  ...  orig_Y_COR  mut_Y_COR  \\\n",
       "0              0          0           0  ...           0          0   \n",
       "1              0          0           0  ...           0          0   \n",
       "2              0          0           0  ...           0          0   \n",
       "3              0          0           0  ...           0          0   \n",
       "4              0          0           0  ...           0          0   \n",
       "...          ...        ...         ...  ...         ...        ...   \n",
       "7080           0          0           0  ...           0          0   \n",
       "7081           0          1           0  ...           0          0   \n",
       "7082           0          0           0  ...           0          0   \n",
       "7083           0          0           0  ...           0          0   \n",
       "7084           0          0           0  ...           1          0   \n",
       "\n",
       "      orig_Y_INT  mut_Y_INT  orig_Y_SUR  mut_Y_SUR  orig_Y_RIM  mut_Y_RIM  \\\n",
       "0              0          0           0          0           0          0   \n",
       "1              0          0           0          0           0          0   \n",
       "2              0          0           0          0           0          0   \n",
       "3              0          0           0          0           0          0   \n",
       "4              0          0           0          0           0          0   \n",
       "...          ...        ...         ...        ...         ...        ...   \n",
       "7080           0          0           0          0           0          0   \n",
       "7081           0          0           0          0           0          0   \n",
       "7082           0          0           0          0           0          0   \n",
       "7083           0          0           0          0           0          0   \n",
       "7084           0          0           0          0           0          0   \n",
       "\n",
       "      orig_Y_SUP  mut_Y_SUP  \n",
       "0              0          0  \n",
       "1              0          0  \n",
       "2              0          0  \n",
       "3              0          0  \n",
       "4              0          0  \n",
       "...          ...        ...  \n",
       "7080           0          0  \n",
       "7081           0          0  \n",
       "7082           0          0  \n",
       "7083           0          0  \n",
       "7084           0          0  \n",
       "\n",
       "[6794 rows x 207 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Список всех аминокислот (однобуквенные коды)\n",
    "amino_acids = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', \n",
    "               'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "\n",
    "# Список всех возможных позиций\n",
    "locations = ['COR', 'INT', 'SUR', 'RIM', 'SUP']\n",
    "\n",
    "# Создаем DataFrame с нулями для всех новых столбцов\n",
    "new_columns = []\n",
    "for aa in amino_acids:\n",
    "    for loc in locations:\n",
    "        new_columns.append(f'orig_{aa}_{loc}')\n",
    "        new_columns.append(f'mut_{aa}_{loc}')\n",
    "\n",
    "# Создаем DataFrame с нулевыми значениями для всех новых столбцов\n",
    "new_data = pd.DataFrame(0, index=data.index, columns=new_columns)\n",
    "\n",
    "# Объединяем с исходным DataFrame\n",
    "data = pd.concat([data, new_data], axis=1)\n",
    "\n",
    "# Проходим по каждой строке датафрейма\n",
    "for idx, row in data.iterrows():\n",
    "    mutations = str(row['Mutation(s)_cleaned']).split(',') if pd.notna(row['Mutation(s)_cleaned']) else []\n",
    "    mutation_locations = str(row['iMutation_Location(s)']).split(',') if pd.notna(row['iMutation_Location(s)']) else []\n",
    "    \n",
    "    # Очищаем от пробелов\n",
    "    mutations = [m.strip() for m in mutations]\n",
    "    mutation_locations = [ml.strip() for ml in mutation_locations]\n",
    "    \n",
    "    # Для каждой мутации и соответствующей локации\n",
    "    for i in range(min(len(mutations), len(mutation_locations))):\n",
    "        mut = mutations[i]\n",
    "        loc = mutation_locations[i]\n",
    "        \n",
    "        if len(mut) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Извлекаем первую и последнюю буквы мутации\n",
    "        orig_aa = mut[0]\n",
    "        mut_aa = mut[-1]\n",
    "        \n",
    "        # Устанавливаем 1 в соответствующих столбцах\n",
    "        if orig_aa in amino_acids and loc in locations:\n",
    "            data.loc[idx, f'orig_{orig_aa}_{loc}'] = 1\n",
    "        if mut_aa in amino_acids and loc in locations:\n",
    "            data.loc[idx, f'mut_{mut_aa}_{loc}'] = 1\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb884d8d-96b4-4f45-b6c6-b162a186c552",
   "metadata": {},
   "source": [
    "Предобработаем мутации, а именно оставим исходные аминокислоты и те, на которые они были заменены и учтем где именно эти замены произошли. Сделаем своего рода One Hot Encoding только создадим 200 столбцов: 20 вариантов аминокислот * 5 вариантов положения в белке * оригинальная или мутированная. И проставим наличие (возможно множетсвенное) оригинальных аминокислот и мутированных как просто есть - 1 - нет - 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e34b4d-7e77-401b-a96f-b7786b30d3e1",
   "metadata": {},
   "source": [
    "We will preprocess the mutations by extracting the original amino acids and the ones they were substituted with, along with their positions in the protein. \n",
    "\n",
    "Instead of traditional one-hot encoding, we will create a custom binary encoding with 200 columns defined as follows:\n",
    "- 20 amino acid types\n",
    "- 5 positional categories in the protein (e.g., interface core, rim, support, interior, surface)\n",
    "- Two states: original amino acid and mutated amino acid\n",
    "\n",
    "For each mutation, the corresponding columns will be set to 1 (presence), and 0 otherwise. Multiple mutations in one entry will be encoded cumulatively, marking each observed original and mutated amino acid at their respective positions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7516b15f-f021-4df3-88d8-16b92987058e",
   "metadata": {},
   "source": [
    "Найдем все необходимые $\\Delta G$, расчитаем ∆∆G.\n",
    "\n",
    "Find all necessary $\\Delta G$ values, calculate ∆∆G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7990879a-b2f9-4647-bd56-2231fc7c8bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein 1</th>\n",
       "      <th>Protein 2</th>\n",
       "      <th>orig_A_COR</th>\n",
       "      <th>mut_A_COR</th>\n",
       "      <th>orig_A_INT</th>\n",
       "      <th>mut_A_INT</th>\n",
       "      <th>orig_A_SUR</th>\n",
       "      <th>mut_A_SUR</th>\n",
       "      <th>orig_A_RIM</th>\n",
       "      <th>mut_A_RIM</th>\n",
       "      <th>...</th>\n",
       "      <th>mut_Y_COR</th>\n",
       "      <th>orig_Y_INT</th>\n",
       "      <th>mut_Y_INT</th>\n",
       "      <th>orig_Y_SUR</th>\n",
       "      <th>mut_Y_SUR</th>\n",
       "      <th>orig_Y_RIM</th>\n",
       "      <th>mut_Y_RIM</th>\n",
       "      <th>orig_Y_SUP</th>\n",
       "      <th>mut_Y_SUP</th>\n",
       "      <th>ddG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9409.119296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4904.605045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27912.620681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12305.091991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subtilisin Carlsberg</td>\n",
       "      <td>Eglin c</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18202.214523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9355.041398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13126.962754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4498.558971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5117.948598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7084</th>\n",
       "      <td>I-Ek plus MCC peptide</td>\n",
       "      <td>2B4 TCR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5089.239447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6794 rows × 203 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Protein 1 Protein 2  orig_A_COR  mut_A_COR  orig_A_INT  \\\n",
       "0      Subtilisin Carlsberg   Eglin c           0          0           0   \n",
       "1      Subtilisin Carlsberg   Eglin c           0          0           0   \n",
       "2      Subtilisin Carlsberg   Eglin c           0          0           0   \n",
       "3      Subtilisin Carlsberg   Eglin c           0          0           0   \n",
       "4      Subtilisin Carlsberg   Eglin c           0          0           0   \n",
       "...                     ...       ...         ...        ...         ...   \n",
       "7080  I-Ek plus MCC peptide   2B4 TCR           0          0           0   \n",
       "7081  I-Ek plus MCC peptide   2B4 TCR           0          1           0   \n",
       "7082  I-Ek plus MCC peptide   2B4 TCR           0          0           0   \n",
       "7083  I-Ek plus MCC peptide   2B4 TCR           0          0           0   \n",
       "7084  I-Ek plus MCC peptide   2B4 TCR           0          0           0   \n",
       "\n",
       "      mut_A_INT  orig_A_SUR  mut_A_SUR  orig_A_RIM  mut_A_RIM  ...  mut_Y_COR  \\\n",
       "0             0           0          0           0          0  ...          0   \n",
       "1             0           0          0           0          0  ...          0   \n",
       "2             0           0          0           0          0  ...          0   \n",
       "3             0           0          0           0          0  ...          0   \n",
       "4             0           0          0           0          0  ...          0   \n",
       "...         ...         ...        ...         ...        ...  ...        ...   \n",
       "7080          0           0          0           0          0  ...          0   \n",
       "7081          0           0          0           0          0  ...          0   \n",
       "7082          0           0          0           0          0  ...          0   \n",
       "7083          0           0          0           0          0  ...          0   \n",
       "7084          0           0          0           0          0  ...          0   \n",
       "\n",
       "      orig_Y_INT  mut_Y_INT  orig_Y_SUR  mut_Y_SUR  orig_Y_RIM  mut_Y_RIM  \\\n",
       "0              0          0           0          0           0          0   \n",
       "1              0          0           0          0           0          0   \n",
       "2              0          0           0          0           0          0   \n",
       "3              0          0           0          0           0          0   \n",
       "4              0          0           0          0           0          0   \n",
       "...          ...        ...         ...        ...         ...        ...   \n",
       "7080           0          0           0          0           0          0   \n",
       "7081           0          0           0          0           0          0   \n",
       "7082           0          0           0          0           0          0   \n",
       "7083           0          0           0          0           0          0   \n",
       "7084           0          0           0          0           0          0   \n",
       "\n",
       "      orig_Y_SUP  mut_Y_SUP           ddG  \n",
       "0              0          0   9409.119296  \n",
       "1              0          0   4904.605045  \n",
       "2              0          0  27912.620681  \n",
       "3              0          0  12305.091991  \n",
       "4              0          0  18202.214523  \n",
       "...          ...        ...           ...  \n",
       "7080           0          0   9355.041398  \n",
       "7081           0          0  13126.962754  \n",
       "7082           0          0   4498.558971  \n",
       "7083           0          0   5117.948598  \n",
       "7084           0          0   5089.239447  \n",
       "\n",
       "[6794 rows x 203 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Temperature'] = data['Temperature'].astype(str).str.replace(r'\\(.*\\)', '', regex=True)\n",
    "data['Temperature'] = pd.to_numeric(data['Temperature'])\n",
    "data['Affinity_mut_parsed'] = pd.to_numeric(data['Affinity_mut_parsed'])\n",
    "data['Affinity_wt_parsed'] = pd.to_numeric(data['Affinity_wt_parsed'])\n",
    "data['dG(mut)'] = 8.314 * data['Temperature'] * np.log(data['Affinity_mut_parsed'])\n",
    "data['dG(wt)'] = 8.314 * data['Temperature'] * np.log(data['Affinity_wt_parsed'])\n",
    "data['ddG'] = data['dG(mut)'] - data['dG(wt)']\n",
    "data_for_ML = data.drop(columns =['Mutation(s)_cleaned', 'Affinity_mut_parsed', 'Affinity_wt_parsed', 'Temperature', \n",
    "                                  'dG(mut)', 'dG(wt)', 'iMutation_Location(s)'])\n",
    "data_for_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdfab007-71ae-4048-a4bc-738d003eddca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Protein 1', 'Protein 2'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_ML.drop(columns = data_for_ML.columns[2:203]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29d75d-6e7f-46e6-a04c-7f46a8186b17",
   "metadata": {},
   "source": [
    "Сделаем one hot encoding для белков, которые входят в комплекс.\n",
    "\n",
    "Let's perform one-hot encoding for the proteins that are part of the complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2276d4c9-2528-4831-8b9e-673098321106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_A_COR</th>\n",
       "      <th>mut_A_COR</th>\n",
       "      <th>orig_A_INT</th>\n",
       "      <th>mut_A_INT</th>\n",
       "      <th>orig_A_SUR</th>\n",
       "      <th>mut_A_SUR</th>\n",
       "      <th>orig_A_RIM</th>\n",
       "      <th>mut_A_RIM</th>\n",
       "      <th>orig_A_SUP</th>\n",
       "      <th>mut_A_SUP</th>\n",
       "      <th>...</th>\n",
       "      <th>Protein 2_VavS</th>\n",
       "      <th>Protein 2_YAe62 TCR</th>\n",
       "      <th>Protein 2_ZipA</th>\n",
       "      <th>Protein 2_a24b17 TCR</th>\n",
       "      <th>Protein 2_eOD-GT6</th>\n",
       "      <th>Protein 2_erbB-2</th>\n",
       "      <th>Protein 2_gp120</th>\n",
       "      <th>Protein 2_hGH binding protein</th>\n",
       "      <th>Protein 2_p67phox</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7080</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7084</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6794 rows × 570 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      orig_A_COR  mut_A_COR  orig_A_INT  mut_A_INT  orig_A_SUR  mut_A_SUR  \\\n",
       "0              0          0           0          0           0          0   \n",
       "1              0          0           0          0           0          0   \n",
       "2              0          0           0          0           0          0   \n",
       "3              0          0           0          0           0          0   \n",
       "4              0          0           0          0           0          0   \n",
       "...          ...        ...         ...        ...         ...        ...   \n",
       "7080           0          0           0          0           0          0   \n",
       "7081           0          1           0          0           0          0   \n",
       "7082           0          0           0          0           0          0   \n",
       "7083           0          0           0          0           0          0   \n",
       "7084           0          0           0          0           0          0   \n",
       "\n",
       "      orig_A_RIM  mut_A_RIM  orig_A_SUP  mut_A_SUP  ...  Protein 2_VavS  \\\n",
       "0              0          0           0          0  ...             0.0   \n",
       "1              0          0           0          0  ...             0.0   \n",
       "2              0          0           0          0  ...             0.0   \n",
       "3              0          0           0          0  ...             0.0   \n",
       "4              0          0           0          0  ...             0.0   \n",
       "...          ...        ...         ...        ...  ...             ...   \n",
       "7080           0          0           0          0  ...             0.0   \n",
       "7081           0          0           0          0  ...             0.0   \n",
       "7082           0          0           0          0  ...             0.0   \n",
       "7083           0          0           0          0  ...             0.0   \n",
       "7084           0          0           0          0  ...             0.0   \n",
       "\n",
       "      Protein 2_YAe62 TCR  Protein 2_ZipA  Protein 2_a24b17 TCR  \\\n",
       "0                     0.0             0.0                   0.0   \n",
       "1                     0.0             0.0                   0.0   \n",
       "2                     0.0             0.0                   0.0   \n",
       "3                     0.0             0.0                   0.0   \n",
       "4                     0.0             0.0                   0.0   \n",
       "...                   ...             ...                   ...   \n",
       "7080                  0.0             0.0                   0.0   \n",
       "7081                  0.0             0.0                   0.0   \n",
       "7082                  0.0             0.0                   0.0   \n",
       "7083                  0.0             0.0                   0.0   \n",
       "7084                  0.0             0.0                   0.0   \n",
       "\n",
       "      Protein 2_eOD-GT6  Protein 2_erbB-2  Protein 2_gp120  \\\n",
       "0                   0.0               0.0              0.0   \n",
       "1                   0.0               0.0              0.0   \n",
       "2                   0.0               0.0              0.0   \n",
       "3                   0.0               0.0              0.0   \n",
       "4                   0.0               0.0              0.0   \n",
       "...                 ...               ...              ...   \n",
       "7080                0.0               0.0              0.0   \n",
       "7081                0.0               0.0              0.0   \n",
       "7082                0.0               0.0              0.0   \n",
       "7083                0.0               0.0              0.0   \n",
       "7084                0.0               0.0              0.0   \n",
       "\n",
       "      Protein 2_hGH binding protein  Protein 2_p67phox  Classes  \n",
       "0                               0.0                0.0        1  \n",
       "1                               0.0                0.0        1  \n",
       "2                               0.0                0.0        1  \n",
       "3                               0.0                0.0        1  \n",
       "4                               0.0                0.0        1  \n",
       "...                             ...                ...      ...  \n",
       "7080                            0.0                0.0        1  \n",
       "7081                            0.0                0.0        1  \n",
       "7082                            0.0                0.0        1  \n",
       "7083                            0.0                0.0        1  \n",
       "7084                            0.0                0.0        1  \n",
       "\n",
       "[6794 rows x 570 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "ML_data=data_for_ML.copy()\n",
    "for column in data_for_ML.drop(columns = data_for_ML.columns[2:403]).columns:\n",
    "    one_hot_array = ohe.fit_transform(data_for_ML[[column]])\n",
    "    one_hot_df = pd.DataFrame(one_hot_array, columns=ohe.get_feature_names_out([column]), index=data_for_ML.index)\n",
    "    ML_data=ML_data.join(one_hot_df, how='left')\n",
    "ML_data['Classes'] = (ML_data['ddG'] > 0).astype(int)\n",
    "ML_data.drop(columns = ['Protein 1','Protein 2', 'ddG'], inplace = True)\n",
    "ML_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbb7b7-8668-441c-bedb-5c7f61e8a947",
   "metadata": {},
   "source": [
    "Попробуем построить модель, которая будет стараться по положению мутантного остатка на определенном типе сайта взаимодействия двух белков, классифицированого на support, core, rim, interior or surface предсказать изменение ddG. Просто если смотреть на непосредственно сами мутации качественно и на их конкретное положение в пдб, то как убдто простейшей моделью машинного обучения здесь не обойтись. Также при изучении бд я заметила, что помимо одиночных мутаций есть еще мутации в нескольких аминокислотных остатках, но тк дано только суммарное изменение dG, то в модели такие множественные мутации будут идти как отельные классы, поскольку нельзя отделить влияние одного от другого, а суть можно только по совокупности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672bc3f-c5ff-4f35-815e-c43c6982aec2",
   "metadata": {},
   "source": [
    "Let's try to build a model that will attempt to predict the change in ddG based on the position of the mutant residue at a specific type of interaction site between two proteins, classified as support, core, rim, interior, or surface.\n",
    "\n",
    "The rationale is that if we look qualitatively at the mutations themselves and their specific positions in the PDB, it seems that even the simplest machine learning model won't suffice here. Furthermore, while studying the database, I noticed that in addition to single mutations, there are also mutations in multiple amino acid residues. However, since only the total change in dG is provided, such multiple mutations will be treated as distinct classes in the model. This is because the individual contribution of each mutation cannot be isolated; their influence can only be understood in aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b51f4074-93d2-4d28-92b7-ffe0ccdef5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8999290a-d7db-4242-bce4-81954cd8db6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML=ML_data.drop(columns = ['Classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91731259-e0d8-4233-9a9d-f602747b2b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5157"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сколько ddG с положительным знаком (класс 1)\n",
    "# Count ddG values with a positive sign (class 1)\n",
    "(ML_data['Classes'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eabaf6d-ffc6-4ea4-9001-7987778c184e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сколько ddG с отрицательным знаком (класс 1)\n",
    "# Count ddG values with a negative sign (class 0)\n",
    "(ML_data['Classes'] == 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312fd9ef-32bd-40cf-b483-21e9dea6db01",
   "metadata": {},
   "source": [
    "В классах явно преобладает тот, который отвечает за положительное изменение ddG, поэтому в выборке будет наблюдается небалансированность классов, что в целом логично, поскольку чаще всего мутации в белках приводят к их дестабилизации и уеньшению аффинности. Для обучения моделей по возможности везде сразу выставим `class_weight='balanced'`, но далее проверим насколько правилен этот гиперпараметр при помощи `GridSearchCV`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64daf618-8da1-4878-8579-bc6c19901863",
   "metadata": {},
   "source": [
    "One class clearly predominates—the one corresponding to a positive change in ddG. Therefore, the dataset exhibits class imbalance, which is generally logical since mutations in proteins most often lead to their destabilization and reduced affinity. For training models, we will set `class_weight='balanced'` wherever possible right away, but later we will check how appropriate this hyperparameter is using `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "664029b5-d04b-4f7f-b22f-a25e4119ce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# разобьем выборку на train и test\n",
    "# Split the dataset into train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(ML, ML_data['Classes'], test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bdde9ee-8b00-427f-9557-edf26686b597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight='balanced')\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59       320\n",
      "           1       0.88      0.84      0.86      1039\n",
      "\n",
      "    accuracy                           0.79      1359\n",
      "   macro avg       0.72      0.74      0.73      1359\n",
      "weighted avg       0.81      0.79      0.80      1359\n",
      "\n",
      "RandomForestClassifier(class_weight='balanced')\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.53      0.58       320\n",
      "           1       0.86      0.91      0.89      1039\n",
      "\n",
      "    accuracy                           0.82      1359\n",
      "   macro avg       0.76      0.72      0.74      1359\n",
      "weighted avg       0.81      0.82      0.82      1359\n",
      "\n",
      "GradientBoostingClassifier()\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.17      0.27       320\n",
      "           1       0.79      0.98      0.88      1039\n",
      "\n",
      "    accuracy                           0.79      1359\n",
      "   macro avg       0.76      0.57      0.57      1359\n",
      "weighted avg       0.78      0.79      0.73      1359\n",
      "\n",
      "LogisticRegression(class_weight='balanced')\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.68      0.51       320\n",
      "           1       0.88      0.69      0.77      1039\n",
      "\n",
      "    accuracy                           0.69      1359\n",
      "   macro avg       0.64      0.69      0.64      1359\n",
      "weighted avg       0.76      0.69      0.71      1359\n",
      "\n",
      "SVC(class_weight='balanced')\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.71      0.60       320\n",
      "           1       0.90      0.81      0.85      1039\n",
      "\n",
      "    accuracy                           0.78      1359\n",
      "   macro avg       0.71      0.76      0.73      1359\n",
      "weighted avg       0.81      0.78      0.79      1359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(class_weight='balanced')\n",
    "rf = RandomForestClassifier(class_weight='balanced') #\n",
    "gb = GradientBoostingClassifier()\n",
    "lg = LogisticRegression(class_weight='balanced')\n",
    "svm = SVC(class_weight='balanced')\n",
    "\n",
    "\n",
    "classifiers = [dtc, rf, gb, lg, svm]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    clf = classifier \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(classifier)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957733f-1d99-45b4-b2cd-266ed024af46",
   "metadata": {},
   "source": [
    "Для оценки моделей, на мой взгляд, имеет смысл смотреть в основном на 2 метрики: f1-score и accuracy. Такой выбор обусловлен тем, что:\n",
    "1. precision (точность) - доля правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом;\n",
    "2. recall (полнота) - доля правильно найденных положительных объектов среди всех объектов положительного класса;\n",
    "3. f1-score - среднее гармоническое precision и recall;\n",
    "4. accuracy - доля объектов, для которых мы правильно предсказали класс.\n",
    "\n",
    "Таким образом, accuracy дает нам общее представление о предсказательной способности модели, однако только ее не хватает, поскольку она не учитывает дисбаланс классов. И f1-score как раз учитывает эту особенность нашей выборки, а также при использовании данной метрики мы учитываем, и precision, и recall.\n",
    "\n",
    "Рвссматривая результаты выше, можно сказать, что достаточно хороший результат по обеим метрикам дают модели DecisionTreeClassifier, RandomForestClassifier и SVC. Для остальных классификаторов (LogisticRegression и GradientBoostingClassifier) наблюдается достаточно низкая предсказательная способность 0-ого класса (мутации, имеющие ddG < 0)\n",
    "\n",
    "\n",
    "Попробуем улучшить метрики для всех классов путем устранения проблемы несбаллансированности классов при помощи методов undersampling и oversampling и сравним результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e006498-5207-45f8-bc4c-db967e6439ec",
   "metadata": {},
   "source": [
    "When evaluating models, it makes sense to primarily focus on two metrics: f1-score and accuracy. This choice is justified by the following:\n",
    "\n",
    "1.  **Precision**: The proportion of correctly predicted positive instances among all instances predicted as the positive class.\n",
    "2.  **Recall**: The proportion of correctly identified positive instances among all actual positive class instances.\n",
    "3.  **F1-score**: The harmonic mean of precision and recall.\n",
    "4.  **Accuracy**: The proportion of instances for which we correctly predicted the class.\n",
    "\n",
    "Thus, accuracy gives us a general idea of the model's predictive ability, but it is insufficient on its own because it does not account for class imbalance. The f1-score, however, does account for this characteristic of our dataset, and by using this metric, we consider both precision and recall.\n",
    "\n",
    "Looking at the results above, we can say that the DecisionTreeClassifier, RandomForestClassifier, and SVC models yield reasonably good results for both metrics. The other classifiers (LogisticRegression and GradientBoostingClassifier) show a rather low predictive ability for class 0 (mutations with ddG < 0).\n",
    "\n",
    "Let's try to improve the metrics for all classes by addressing the class imbalance problem using undersampling and oversampling methods, and then compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8099b4e0-a42a-407a-a467-368e4949bed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Applying RandomOverSampler ===\n",
      "\n",
      "--- Evaluating DecisionTreeClassifier(class_weight='balanced') with RandomOverSampler ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.62      0.59       320\n",
      "           1       0.88      0.85      0.86      1039\n",
      "\n",
      "    accuracy                           0.79      1359\n",
      "   macro avg       0.72      0.73      0.72      1359\n",
      "weighted avg       0.80      0.79      0.80      1359\n",
      "\n",
      "\n",
      "--- Evaluating RandomForestClassifier(class_weight='balanced') with RandomOverSampler ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61       320\n",
      "           1       0.88      0.87      0.88      1039\n",
      "\n",
      "    accuracy                           0.81      1359\n",
      "   macro avg       0.74      0.75      0.74      1359\n",
      "weighted avg       0.82      0.81      0.81      1359\n",
      "\n",
      "\n",
      "--- Evaluating GradientBoostingClassifier() with RandomOverSampler ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.78      0.52       320\n",
      "           1       0.90      0.63      0.74      1039\n",
      "\n",
      "    accuracy                           0.67      1359\n",
      "   macro avg       0.65      0.70      0.63      1359\n",
      "weighted avg       0.78      0.67      0.69      1359\n",
      "\n",
      "\n",
      "--- Evaluating LogisticRegression(class_weight='balanced') with RandomOverSampler ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.68      0.50       320\n",
      "           1       0.87      0.69      0.77      1039\n",
      "\n",
      "    accuracy                           0.68      1359\n",
      "   macro avg       0.64      0.68      0.63      1359\n",
      "weighted avg       0.76      0.68      0.71      1359\n",
      "\n",
      "\n",
      "--- Evaluating SVC(class_weight='balanced') with RandomOverSampler ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.69      0.62       320\n",
      "           1       0.90      0.83      0.86      1039\n",
      "\n",
      "    accuracy                           0.80      1359\n",
      "   macro avg       0.73      0.76      0.74      1359\n",
      "weighted avg       0.82      0.80      0.81      1359\n",
      "\n",
      "\n",
      "=== Applying RandomUnderSampler ===\n",
      "\n",
      "--- Evaluating DecisionTreeClassifier(class_weight='balanced') with RandomUnderSampler ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.75      0.54       320\n",
      "           1       0.90      0.68      0.78      1039\n",
      "\n",
      "    accuracy                           0.70      1359\n",
      "   macro avg       0.66      0.72      0.66      1359\n",
      "weighted avg       0.79      0.70      0.72      1359\n",
      "\n",
      "\n",
      "--- Evaluating RandomForestClassifier(class_weight='balanced') with RandomUnderSampler ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.75      0.58       320\n",
      "           1       0.91      0.74      0.81      1039\n",
      "\n",
      "    accuracy                           0.74      1359\n",
      "   macro avg       0.69      0.74      0.69      1359\n",
      "weighted avg       0.80      0.74      0.76      1359\n",
      "\n",
      "\n",
      "--- Evaluating GradientBoostingClassifier() with RandomUnderSampler ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.78      0.51       320\n",
      "           1       0.90      0.60      0.72      1039\n",
      "\n",
      "    accuracy                           0.64      1359\n",
      "   macro avg       0.64      0.69      0.61      1359\n",
      "weighted avg       0.78      0.64      0.67      1359\n",
      "\n",
      "\n",
      "--- Evaluating LogisticRegression(class_weight='balanced') with RandomUnderSampler ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.70      0.50       320\n",
      "           1       0.88      0.67      0.76      1039\n",
      "\n",
      "    accuracy                           0.67      1359\n",
      "   macro avg       0.63      0.68      0.63      1359\n",
      "weighted avg       0.76      0.67      0.70      1359\n",
      "\n",
      "\n",
      "--- Evaluating SVC(class_weight='balanced') with RandomUnderSampler ---\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.74      0.57       320\n",
      "           1       0.90      0.73      0.81      1039\n",
      "\n",
      "    accuracy                           0.73      1359\n",
      "   macro avg       0.68      0.74      0.69      1359\n",
      "weighted avg       0.80      0.73      0.75      1359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# заново объявим классификаторы\n",
    "# Let's redeclare the classifiers.\n",
    "dtc = tree.DecisionTreeClassifier(class_weight='balanced')\n",
    "rf = RandomForestClassifier(class_weight='balanced') #\n",
    "gb = GradientBoostingClassifier()\n",
    "lg = LogisticRegression(class_weight='balanced')\n",
    "svm = SVC(class_weight='balanced')\n",
    "\n",
    "\n",
    "classifiers = [dtc, rf, gb, lg, svm]\n",
    "\n",
    "\n",
    "# Определим методы сэмплинга\n",
    "# Let's define the sampling methods.\n",
    "samplers = [\n",
    "    ('RandomOverSampler', RandomOverSampler(random_state=42)),\n",
    "    ('RandomUnderSampler', RandomUnderSampler(random_state=42))\n",
    "]\n",
    "\n",
    "# Сделаем перебор по методам сэмплинга и по классфикаторам\n",
    "# Let's iterate over sampling methods and classifiers.\n",
    "for sampler_name, sampler in samplers:\n",
    "    print(f\"\\n=== Applying {sampler_name} ===\")\n",
    "    \n",
    "    # применим сэмплинг для уже имеющихся трейн и тест выборок\n",
    "    # Apply sampling to the existing train and test sets.\n",
    "    Xr_train, yr_train = sampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    for classifier in classifiers:\n",
    "        print(f\"\\n--- Evaluating {classifier} with {sampler_name} ---\")\n",
    "        \n",
    "        # Обучение и предсказание\n",
    "        # Training and prediction.\n",
    "        classifier.fit(Xr_train, yr_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886ceca9-51eb-4f5f-8593-3f490dccece9",
   "metadata": {},
   "source": [
    "В целом метрики улучшились для случая oversampling-а. Однако с ним есть риск переобучения, а в случае undersampling-a, в силу случайности убираемых данных, можно убрать уникальные данные, что это риковано потерей в качестве модели. Поэтому сделаем cross-validation и grid search (при помощи класса`sklearn.model_selection.GridSearchCV`) для случая oversampling-а. Чтобы подобрать наиболее удачные гиперпараметры, я разбила DataFrame на train и test. И на train-e я сделала жадный перебор по сетке гиперпараметров моделей. Чтобы сделать полный перебор у меня не хватает локальных вычислительных ресурсов, поэтому я выбрала первые 3-4 гиперпараметра из документации + class_weight, чтобы оценить насколько хорошими были модели выше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4115999b-c82c-4b21-bb95-facdee03a332",
   "metadata": {},
   "source": [
    "Overall, the metrics improved for the oversampling case. However, there is a risk of overfitting with it, while in the case of undersampling, due to the randomness of the removed data, unique data might be eliminated, which risks a loss in model quality. Therefore, we will perform cross-validation and grid search (using the `sklearn.model_selection.GridSearchCV` class) for the oversampling case.\n",
    "\n",
    "To find the most suitable hyperparameters, I split the DataFrame into train and test sets. On the train set, I performed a greedy grid search over the model hyperparameters. I don't have enough local computational resources for a full exhaustive search, so I selected the first 3-4 hyperparameters from the documentation, plus class_weight, to evaluate how good the previous models were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f793e3c-cb9b-4af3-a9ba-ae282d565f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим новые трейн и тест, но заоверсэмплим прейн. Обучим модели заново\n",
    "# Create new train and test sets, but apply oversampling only to the train set. Retrain the models.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ML, ML_data['Classes'], test_size=0.2, shuffle=True, random_state=42)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "gb = GradientBoostingClassifier()\n",
    "lg = LogisticRegression(max_iter=5000, tol=1e-4, random_state=42)\n",
    "svm = SVC(max_iter=50000, tol=1e-4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47e6091a-c5a6-41ac-af68-1214f40ec9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем грид серч\n",
    "# grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4723e95e-40f4-4a70-8e24-6d316c18b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77656495-102b-4aff-82dd-89eedc559608",
   "metadata": {},
   "source": [
    "RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1f32318-7be2-4618-b353-5a45b676641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters: {'class_weight': None, 'max_depth': None, 'n_estimators': 500}\n",
      "Best f1 score: 0.8812\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [50, 100, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=params, cv=5, scoring='f1', n_jobs=-1, verbose=1, refit = True)\n",
    "grid_search.fit(X_train_over, y_train_over)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")  \n",
    "print(f\"Best f1 score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "746c764a-449b-4724-84b8-63159568a463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.61      0.60       320\n",
      "           1       0.88      0.87      0.87      1039\n",
      "\n",
      "    accuracy                           0.81      1359\n",
      "   macro avg       0.73      0.74      0.74      1359\n",
      "weighted avg       0.81      0.81      0.81      1359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# оценим модель с новыми гиперпараметрами\n",
    "# Evaluate the model with the new hyperparameters.\n",
    "\n",
    "rf1 = RandomForestClassifier(**grid_search.best_params_)\n",
    "rf1.fit(X_train_over, y_train_over)\n",
    "y_pred = rf1.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84afa1c1-249d-4bf2-b279-d90605b3f81a",
   "metadata": {},
   "source": [
    "GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d61b85a-43b1-495b-a700-8c848b9dfd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 1, 'n_estimators': 300}\n",
      "Best f1 score: 0.8425\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gb, param_grid=params, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_over, y_train_over)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best f1 score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84a9d1cf-46a9-4549-8c5a-1ec4d8d5eecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.69      0.59       320\n",
      "           1       0.89      0.80      0.84      1039\n",
      "\n",
      "    accuracy                           0.77      1359\n",
      "   macro avg       0.71      0.75      0.72      1359\n",
      "weighted avg       0.81      0.77      0.79      1359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# оценим модель с новыми гиперпараметрами\n",
    "# Evaluate the model with the new hyperparameters.\n",
    "gb1 = GradientBoostingClassifier(**grid_search.best_params_)\n",
    "gb1.fit(X_train_over, y_train_over)\n",
    "y_pred = gb1.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50d18b9-3c12-4a06-aa6e-134212363f88",
   "metadata": {},
   "source": [
    "LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "756590e7-1210-447c-abc7-a0522a89f09f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1186: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "120 fits failed out of a total of 240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "60 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Applications/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.65605767        nan 0.73690168        nan 0.65597472\n",
      "        nan 0.73716791        nan 0.69254772        nan 0.73690168\n",
      "        nan 0.69263619        nan 0.73716791        nan 0.71820233\n",
      "        nan 0.73690168        nan 0.71884231        nan 0.73716791\n",
      "        nan 0.72943308        nan 0.73690168        nan 0.72965086\n",
      "        nan 0.73716791        nan 0.73607711        nan 0.73690168\n",
      "        nan 0.73609858        nan 0.73716791        nan 0.73790661\n",
      "        nan 0.73690168        nan 0.73701571        nan 0.73716791]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100, 'class_weight': None, 'penalty': 'l2'}\n",
      "Best f1 score: 0.7379\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'class_weight': [None, 'balanced']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lg, param_grid=params, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_over, y_train_over)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best f1 score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d354f78-c196-4e13-8ff3-a3242d075faf",
   "metadata": {},
   "source": [
    "При подборе параметров появлялись warnings при вариации penalty=None (поэтому output скрыт). Тем не менее наиболее подходящие параметры следующие:\n",
    "\n",
    "Best parameters: {'C': 100, 'class_weight': None, 'penalty': 'l2'}\n",
    "\n",
    "Best f1 score: 0.7379"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfad7606-d7f9-428f-b94b-0897b8ed85b1",
   "metadata": {},
   "source": [
    "During the parameter tuning, warnings appeared when varying `penalty=None` (therefore, the output is hidden). Nevertheless, the most suitable parameters are as follows:\n",
    "\n",
    "Best parameters: {'C': 100, 'class_weight': None, 'penalty': 'l2'}\n",
    "\n",
    "Best f1 score: 0.7379"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16f906b6-bad7-46b2-b54e-affd9bb361e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.67      0.50       320\n",
      "           1       0.87      0.69      0.77      1039\n",
      "\n",
      "    accuracy                           0.69      1359\n",
      "   macro avg       0.63      0.68      0.63      1359\n",
      "weighted avg       0.76      0.69      0.71      1359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# оценим модель с новыми гиперпараметрами\n",
    "# Evaluate the model with the new hyperparameters.\n",
    "lg1 = LogisticRegression(**grid_search.best_params_)\n",
    "lg1.fit(X_train_over, y_train_over)\n",
    "y_pred = lg1.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef23999-63fd-4ab6-92ef-1f4d7ea52597",
   "metadata": {},
   "source": [
    "SVM (SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9896a55b-ac55-49db-aa9d-94c51ee96167",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/lib/python3.12/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=50000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 10, 'class_weight': None, 'kernel': 'rbf'}\n",
      "Best f1 score: 0.8827\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'class_weight': [None, 'balanced']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=params, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_over, y_train_over)\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best f1 score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a33804c-c774-4e0a-a9ca-671b30136456",
   "metadata": {},
   "source": [
    "При выполнении кода появились warnings, означающие, что при некоторых параметрах модель не сошлась (поэтому output скрыт). Тем  не менее есть те, которые улучшили модель (Best parameters: {'C': 10, 'class_weight': None, 'kernel': 'rbf'}; Best f1 score: 0.8827), поэтому с ними проверим обучение на нашей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87f8ee-ec29-4dc3-b350-36c722ce5d9b",
   "metadata": {},
   "source": [
    "When executing the code, warnings appeared indicating that the model did not converge with some parameters (therefore the output is hidden). Nevertheless, there are parameters that improved the model (Best parameters: {'C': 10, 'class_weight': None, 'kernel': 'rbf'}; Best f1 score: 0.8827), so we will use them to test training on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13b0ee87-9c95-40f1-97f0-36685e77d6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.62      0.62       320\n",
      "           1       0.88      0.88      0.88      1039\n",
      "\n",
      "    accuracy                           0.82      1359\n",
      "   macro avg       0.75      0.75      0.75      1359\n",
      "weighted avg       0.82      0.82      0.82      1359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# оценим модель с новыми гиперпараметрами\n",
    "# Evaluate the model with the new hyperparameters\n",
    "svm1 = SVC(**grid_search.best_params_)\n",
    "svm1.fit(X_train_over, y_train_over)\n",
    "y_pred = svm1.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa30538-c9b4-4b9b-b9e2-70f8841ee042",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c9e4a53-b84a-4131-a07c-03b90c479f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
      "Best parameters: {'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': None, 'splitter': 'best'}\n",
      "Best f1 score: 0.8679\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 3, 5, 10, 20],\n",
    "    'class_weight': [None, 'balanced']}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dtc, param_grid=params, cv=5, scoring='f1', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_over, y_train_over)\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best f1 score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "835ff093-56d5-406e-8cdd-abc8bec4a354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.64      0.60       320\n",
      "           1       0.88      0.85      0.86      1039\n",
      "\n",
      "    accuracy                           0.80      1359\n",
      "   macro avg       0.72      0.74      0.73      1359\n",
      "weighted avg       0.81      0.80      0.80      1359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc1 = tree.DecisionTreeClassifier(**grid_search.best_params_)\n",
    "dtc1.fit(X_train_over, y_train_over)\n",
    "y_pred = dtc1.predict(X_test)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f646ef-4ad5-421e-8b93-ea35d637f0fe",
   "metadata": {},
   "source": [
    "В целом, можно сказать, что метрики по тем или иным параметрам улучшились, особенно это заметно для GradientBoosting. Радует, что почти все модели, кроме логистической регресси, стали присваивать класс с отрицательным ddG лучше чем 50%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20562f94-02ce-4541-8259-5702576a1f58",
   "metadata": {},
   "source": [
    "Overall, it can be said that the metrics have improved with certain parameters, which is particularly noticeable for GradientBoosting. It is encouraging that almost all models, except for logistic regression, have become better at assigning the class with negative ddG, exceeding 50%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
